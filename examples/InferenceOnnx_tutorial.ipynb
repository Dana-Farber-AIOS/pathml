{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4e08d2c-f53e-4366-888d-ab72819b4c2f",
   "metadata": {},
   "source": [
    "# PathML ONNX Tutorial\n",
    "\n",
    "Written by James Wen. James_Wen@dfci.harvard.edu. \n",
    "\n",
    "[![View on GitHub](https://img.shields.io/badge/View-on%20GitHub-lightgrey?logo=github)](https://github.com/Dana-Farber-AIOS/pathml/blob/master/examples/)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is a tutorial on how to use the future ONNX `inference` feature in PathML. \n",
    "\n",
    "Some notes:\n",
    "- The ONNX inference pipeline uses the existing PathML Pipeline and Transforms infrastructure.\n",
    "    - ONNX labels are saved to a `pathml.core.slide_data.SlideData` object as `tiles`.\n",
    "    - Users can iterate over the tiles as they would when using this feature for preprocessing. \n",
    "- Preprocessing images before inference\n",
    "    - Users will need to create their own bespoke `pathml.preprocessing.transforms.transform` method to preprocess images before inference if necessary.\n",
    "    - A guide on how to create preprocessing pipelines is [here](https://pathml.readthedocs.io/en/latest/creating_pipelines.html). \n",
    "    - A guide on how to run preprocessing pipelines is [here](https://pathml.readthedocs.io/en/latest/running_pipelines.html). \n",
    "- ONNX Model Initializers \n",
    "    - ONNX models often have neural network initializers stored in the input graph. This means that the user is expected to specify initializer values when running inference. To solve this issue, we have a function that removes the network initializers from the input graph. This functions is adopted from the `onnxruntime` [github](https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py).  \n",
    "    - We also have a function that checks if the initializers have been removed from the input graph before running inference. Both of these functions are described more below. \n",
    "- When using a model stored remotely on HuggingFace, the model is *downloaded locally* before being used. The user will need to delete the model after running `Pipeline` with a method that comes with the model class. An example of how to do this is below. \n",
    "\n",
    "## Quick Sample Code\n",
    "- Below is an example of how users would use the ONNX inference feature in PathML with a locally stored model.\n",
    "```python\n",
    "# load packages\n",
    "from pathml.core import SlideData\n",
    "\n",
    "from pathml.preprocessing import Pipeline\n",
    "import pathml.preprocessing.transforms as Transforms\n",
    "\n",
    "from pathml.inference import Inference, remove_initializer_from_input\n",
    "\n",
    "# Define slide path\n",
    "slide_path = 'PATH TO SLIDE'\n",
    "\n",
    "# Set path to model \n",
    "model_path = 'PATH TO ONNX MODEL'\n",
    "# Define path to export fixed model\n",
    "new_path = 'PATH TO SAVE NEW ONNX MODEL'\n",
    "\n",
    "# Fix the ONNX model by removing initializers. Save new model to `new_path`. \n",
    "remove_initializer_from_input(model_path, new_path) \n",
    "\n",
    "inference = Inference(model_path = new_path, input_name = 'data', num_classes = 8, model_type = 'segmentation')\n",
    "\n",
    "# Create a transformation list\n",
    "transformation_list = [\n",
    "    inference\n",
    "] \n",
    "\n",
    "# Initialize pathml.core.slide_data.SlideData object\n",
    "wsi = SlideData(slide_path, stain = 'Fluor')\n",
    "\n",
    "# Set up PathML pipeline\n",
    "pipeline = Pipeline(transformation_list)\n",
    "\n",
    "# Run Inference\n",
    "wsi.run(pipeline, tile_size = 1280, level = 0)\n",
    "```\n",
    "\n",
    "- Below is an example of how users would use the ONNX inference feature in PathML with a model stored in the public HuggingFace repository.\n",
    "```python\n",
    "# load packages\n",
    "from pathml.core import SlideData\n",
    "\n",
    "from pathml.preprocessing import Pipeline\n",
    "import pathml.preprocessing.transforms as Transforms\n",
    "\n",
    "from pathml.inference import RemoteTestHoverNet\n",
    "\n",
    "# Define slide path\n",
    "slide_path = 'PATH TO SLIDE'\n",
    "\n",
    "inference = RemoteTestHoverNet()\n",
    "\n",
    "# Create a transformation list\n",
    "transformation_list = [\n",
    "    inference\n",
    "] \n",
    "\n",
    "# Initialize pathml.core.slide_data.SlideData object\n",
    "wsi = SlideData(slide_path)\n",
    "\n",
    "# Set up PathML pipeline\n",
    "pipeline = Pipeline(transformation_list)\n",
    "\n",
    "# Run Inference\n",
    "wsi.run(pipeline, tile_size = 256)\n",
    "\n",
    "# DELETE ONNX MODEL DOWNLOADED FROM HUGGINGFACE\n",
    "inference.remove() \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "886a74a3-b905-40dd-9b3e-4e1b90918f9b",
   "metadata": {},
   "source": [
    "## Load Packages\n",
    "\n",
    "**NOTE**\n",
    "- Please put in your environment name in the following line if you are using a jupyter notebook. If not, you may remove this line. \n",
    "    `os.environ[\"JAVA_HOME\"] = \"/opt/conda/envs/YOUR ENVIRONMENET NAME\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436b91f3-6338-4043-8742-496b354544aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/conda/envs/YOUR ENVIRONMENET NAME\" # TO DO: CHANGE THIS TO YOUR ENVIRONMENT NAME\n",
    "import numpy as np \n",
    "import onnx\n",
    "import onnxruntime as ort \n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from pathml.core import SlideData, Tile\n",
    "from dask.distributed import Client\n",
    "from pathml.preprocessing import Pipeline\n",
    "import pathml.preprocessing.transforms as Transforms\n",
    "\n",
    "from pathml.inference import (\n",
    "    HaloAIInference,\n",
    "    Inference,\n",
    "    InferenceBase,\n",
    "    RemoteTestHoverNet,\n",
    "    check_onnx_clean,\n",
    "    remove_initializer_from_input,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34e9fb8c-0148-4184-ba6b-cf5dae63a869",
   "metadata": {},
   "source": [
    "## ONNX Inference Class and ONNX Model Fixer\n",
    "\n",
    "- Here is the raw code for the functions that handle the initializers in the ONNX model and the classes that run the inference.\n",
    "\n",
    "### Functions to remove initializers and check that initializers have been removed.\n",
    "\n",
    "- `remove_initializer_from_input`\n",
    "    - This function removes any initializers from the input graph of the ONNX model.\n",
    "    - Without removing the initializers from the input graph, users will not be able to run inference.\n",
    "    - Adapted from the `onnxruntime` [github](https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py).  \n",
    "    - Users specify:\n",
    "        - `model_path` (str): path to ONNX model,\n",
    "        - `new_path` (str): path to save adjusted model w/o initializers\n",
    "    - We will run this function on all models placed in our model zoo, so users will not have to run it unless they are working with their own local models.\n",
    "    \n",
    " <br> \n",
    " \n",
    "- `check_onnx_clean`\n",
    "    - Checks if the initializers are in the input graph\n",
    "    - Returns `True` and a `ValueError` if there are initializers in the input graph\n",
    "    - Adapted from the `onnxruntime` [github](https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py). \n",
    "    - Users specify:\n",
    "        - `model_path` (str): path to ONNX model\n",
    "\n",
    " <br> \n",
    "\n",
    " - `convert_pytorch_onnx` \n",
    "    - Converts a PyTorch `.pt` file to `.onnx`\n",
    "    - Wrapper function of the [PyTorch](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html) function to handle the conversion.\n",
    "    - Users specify:\n",
    "        - model_path (torch.nn.Module Model): Pytorch model to be converted,\n",
    "        - dummy_tensor (torch.tensor): dummy input tensor that is an example of what will be passed into the model,\n",
    "        - model_name (str): name of ONNX model created with .onnx at the end,\n",
    "        - opset_version (int): which opset version you want to use to export\n",
    "        - input_name (str): name assigned to dummy_tensor\n",
    "    - Note that the model class must be defined before loading the `.pt` file and set to eval before calling this function. \n",
    "\n",
    "### Inference Classes\n",
    "\n",
    "<br> \n",
    "\n",
    "- `InferenceBase`\n",
    "    - This class inherits from `pathml.preprocessing.transforms.transform`, similar to all of the preprocessing transformations. Inheriting from `transforms.transform` allows us to use the existing `Pipeline` function in PathML which users should be familar with.  \n",
    "    - This is the base class for all Inference classes for ONNX modeling\n",
    "    - Each instance of a class also comes with a `model_card` which specifies certain details of the model in dictionary form. The default parameters are:\n",
    "        -   ```python \n",
    "                self.model_card = {\n",
    "                'name' : None, \n",
    "                'num_classes' : None,\n",
    "                'model_type' : None, \n",
    "                'notes' : None,  \n",
    "                'model_input_notes': None, \n",
    "                'model_output_notes' : None,\n",
    "                'citation': None } \n",
    "            ``` \n",
    "       - Model cards are where important information about the model should be kept. Since they are in dictionary form, the user can add keys and values as they see fit. \n",
    "       - This class also has getter and setter functions to adjust the `model_card`. Certain functions include `get_model_card`, `set_name`, `set_num_classes`, etc. \n",
    " \n",
    "  <br> \n",
    "  \n",
    "- `Inference` \n",
    "    - This class is for when the user wants to use an ONNX model stored locally. \n",
    "    - Calls the `check_onnx_clean` function to check if the model is clean.\n",
    "    - Users specify:\n",
    "        - `model_path` (str): path to ONNX model,\n",
    "        - `input_name` (str): name of input for ONNX model, *defaults to `data`* \n",
    "        - `num_classes` (int): number of outcome classes, \n",
    "        - `model_type` (str): type of model (classification, segmentation) \n",
    "        - `local` (bool): if you are using a local model or a remote model, *defaults to `True`* \n",
    " \n",
    "  <br> \n",
    "  \n",
    "- `HaloAIInference`\n",
    "    - This class inherits from `Inference`\n",
    "    - HaloAI ONNX models always return 20 prediction maps: this class will subset and return the necessary ones. \n",
    "\n",
    "<br> \n",
    "\n",
    "- `RemoteTestHoverNet` \n",
    "    - This class inherits from `Inference` and is the test class for public models hosted on `HuggingFace`. \n",
    "    - `local` is automatically set to `False` \n",
    "    - Our current test model is a HoverNet from [TIAToolbox](https://github.com/TissueImageAnalytics/tiatoolbox)\n",
    "    - Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D. TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.\n",
    "    - Its `model_card` is:\n",
    "        -   ```python \n",
    "                {'name': 'Tiabox HoverNet Test',\n",
    "                 'num_classes': 5,\n",
    "                 'model_type': 'Segmentation',\n",
    "                 'notes': None,\n",
    "                 'model_input_notes': 'Accepts tiles of 256 x 256',\n",
    "                 'model_output_notes': None,\n",
    "                 'citation': 'Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D. TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.'}\n",
    "             ```\n",
    "     \n",
    "### Raw Code\n",
    "\n",
    "Below is the raw code for your convenience. You can also find the raw code on our github. \n",
    "[![View on GitHub](https://img.shields.io/badge/View-on%20GitHub-lightgrey?logo=github)](https://github.com/Dana-Farber-AIOS/pathml/tree/master/pathml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3339cf66-8de6-4af1-9d3e-7312cd69eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initializer_from_input(model_path, new_path):\n",
    "    \"\"\"Removes initializers from HaloAI ONNX models\n",
    "    Taken from https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to ONNX model,\n",
    "        new_path (str): path to save adjusted model w/o initializers,\n",
    "\n",
    "    Returns:\n",
    "        ONNX model w/o initializers to run inference using PathML\n",
    "    \"\"\"\n",
    "\n",
    "    model = onnx.load(model_path)\n",
    "\n",
    "    inputs = model.graph.input\n",
    "    name_to_input = {}\n",
    "    for onnx_input in inputs:\n",
    "        name_to_input[onnx_input.name] = onnx_input\n",
    "\n",
    "    for initializer in model.graph.initializer:\n",
    "        if initializer.name in name_to_input:\n",
    "            inputs.remove(name_to_input[initializer.name])\n",
    "\n",
    "    onnx.save(model, new_path)\n",
    "\n",
    "\n",
    "def check_onnx_clean(model_path):\n",
    "    \"\"\"Checks if the model has had it's initalizers removed from input graph.\n",
    "    Adapted from from https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to ONNX model,\n",
    "\n",
    "    Returns:\n",
    "        Boolean if there are initializers in input graph.\n",
    "    \"\"\"\n",
    "\n",
    "    model = onnx.load(model_path)\n",
    "\n",
    "    inputs = model.graph.input\n",
    "    name_to_input = {}\n",
    "    for onnx_input in inputs:\n",
    "        name_to_input[onnx_input.name] = onnx_input\n",
    "\n",
    "    for initializer in model.graph.initializer:\n",
    "        if initializer.name in name_to_input:\n",
    "            return True\n",
    "\n",
    "\n",
    "def convert_pytorch_onnx(\n",
    "    model, dummy_tensor, model_name, opset_version=10, input_name=\"data\"\n",
    "):\n",
    "    \"\"\"Converts a Pytorch Model to ONNX\n",
    "    Adjusted from https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
    "\n",
    "    You need to define the model class and load the weights before exporting. See URL above for full steps.\n",
    "\n",
    "    Args:\n",
    "        model_path (torch.nn.Module Model): Pytorch model to be converted,\n",
    "        dummy_tensor (torch.tensor): dummy input tensor that is an example of what will be passed into the model,\n",
    "        model_name (str): name of ONNX model created with .onnx at the end,\n",
    "        opset_version (int): which opset version you want to use to export\n",
    "        input_name (str): name assigned to dummy_tensor\n",
    "\n",
    "    Returns:\n",
    "        Exports ONNX model converted from Pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(model, torch.nn.Module):\n",
    "        raise ValueError(\n",
    "            f\"The model is not of type torch.nn.Module. Received {type(model)}.\"\n",
    "        )\n",
    "\n",
    "    if not torch.is_tensor(dummy_tensor):\n",
    "        raise ValueError(\n",
    "            f\"The dummy tensor needs to be a torch tensor. Received {type(dummy_tensor)}.\"\n",
    "        )\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_tensor,\n",
    "        model_name,\n",
    "        export_params=True,\n",
    "        opset_version=opset_version,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[input_name],\n",
    "    )\n",
    "\n",
    "\n",
    "# Base class\n",
    "class InferenceBase(Transforms.Transform):\n",
    "    \"\"\"\n",
    "    Base class for all ONNX Models.\n",
    "    Each transform must operate on a Tile.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_card = {\n",
    "            \"name\": None,\n",
    "            \"num_classes\": None,\n",
    "            \"model_type\": None,\n",
    "            \"notes\": None,\n",
    "            \"model_input_notes\": None,\n",
    "            \"model_output_notes\": None,\n",
    "            \"citation\": None,\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Base class for all ONNX models\"\n",
    "\n",
    "    def get_model_card(self):\n",
    "        return self.model_card\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.model_card[\"name\"] = name\n",
    "\n",
    "    def set_num_classes(self, num):\n",
    "        self.model_card[\"num_classes\"] = num\n",
    "\n",
    "    def set_model_type(self, model_type):\n",
    "        self.model_card[\"model_type\"] = model_type\n",
    "\n",
    "    def set_notes(self, note):\n",
    "        self.model_card[\"notes\"] = note\n",
    "\n",
    "    def set_model_input_notes(self, note):\n",
    "        self.model_card[\"model_input_notes\"] = note\n",
    "\n",
    "    def set_model_output_notes(self, note):\n",
    "        self.model_card[\"model_output_notes\"] = note\n",
    "\n",
    "    def set_citation(self, citation):\n",
    "        self.model_card[\"citation\"] = citation\n",
    "\n",
    "    def reshape(self, image):\n",
    "        \"\"\"standard reshaping of tile image\"\"\"\n",
    "        # flip dimensions\n",
    "        # follows convention used here https://github.com/Dana-Farber-AIOS/pathml/blob/master/pathml/ml/dataset.py\n",
    "\n",
    "        if image.ndim == 3:\n",
    "            # swap axes from HWC to CHW\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            # add a dimesion bc onnx models usually have batch size as first dim: e.g. (1, channel, height, width)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            return image\n",
    "        else:\n",
    "            # in this case, we assume that we have XYZCT channel order\n",
    "            # so we swap axes to TCZYX for batching\n",
    "            # note we are not adding a dim here for batch bc we assume that subsetting will create a batch \"placeholder\" dim\n",
    "            image = image.T\n",
    "\n",
    "            return image\n",
    "\n",
    "    def F(self, target):\n",
    "        \"\"\"functional implementation\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def apply(self, tile):\n",
    "        \"\"\"modify Tile object in-place\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# class to handle local onnx models\n",
    "class Inference(InferenceBase):\n",
    "    \"\"\"Transformation to run inferrence on ONNX model.\n",
    "\n",
    "    Assumptions:\n",
    "        - The ONNX model has been cleaned by `remove_initializer_from_input` first\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to ONNX model w/o initializers,\n",
    "        input_name (str): name of the input the ONNX model accepts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path=None,\n",
    "        input_name=\"data\",\n",
    "        num_classes=None,\n",
    "        model_type=None,\n",
    "        local=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_name = input_name\n",
    "        self.num_classes = num_classes\n",
    "        self.model_type = model_type\n",
    "        self.local = local\n",
    "\n",
    "        if self.local:\n",
    "            # using a local onnx model\n",
    "            self.model_path = model_path\n",
    "        else:\n",
    "            # if using a model from the model zoo, set the local path to a temp file\n",
    "            self.model_path = \"temp.onnx\"\n",
    "\n",
    "        # fill in parts of the model_card with the following info\n",
    "        self.model_card[\"num_classes\"] = self.num_classes\n",
    "        self.model_card[\"model_type\"] = self.model_type\n",
    "\n",
    "        # check if there are initializers in input graph if using a local model\n",
    "        if local:\n",
    "            if check_onnx_clean(model_path):\n",
    "                raise ValueError(\n",
    "                    \"The ONNX model still has graph initializers in the input graph. Use `remove_initializer_from_input` to remove them.\"\n",
    "                )\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.local:\n",
    "            return f\"Class to handle ONNX model locally stored at {self.model_path}\"\n",
    "        else:\n",
    "            return f\"Class to handle a {self.model_card['model_name']} from the PathML model zoo.\"\n",
    "\n",
    "    def inference(self, image):\n",
    "        # reshape the image\n",
    "        image = self.reshape(image)\n",
    "\n",
    "        # load fixed model\n",
    "        onnx_model = onnx.load(self.model_path)\n",
    "\n",
    "        # check tile dimensions match ONNX input dimensions\n",
    "        input_node = onnx_model.graph.input\n",
    "\n",
    "        dimensions = []\n",
    "        for input in input_node:\n",
    "            if input.name == self.input_name:\n",
    "                input_shape = input.type.tensor_type.shape.dim\n",
    "                for dim in input_shape:\n",
    "                    dimensions.append(dim.dim_value)\n",
    "\n",
    "        assert (\n",
    "            image.shape[-1] == dimensions[-1] and image.shape[-2] == dimensions[-2]\n",
    "        ), f\"expecting tile shape of {dimensions[-2]} by {dimensions[-1]}, got {image.shape[-2]} by {image.shape[-1]}\"\n",
    "\n",
    "        # check onnx model\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "\n",
    "        # start an inference session\n",
    "        ort_sess = onnxruntime.InferenceSession(self.model_path)\n",
    "\n",
    "        # create model output, returns a list\n",
    "        model_output = ort_sess.run(None, {self.input_name: image.astype(\"f\")})\n",
    "\n",
    "        return model_output\n",
    "\n",
    "    def F(self, image):\n",
    "        # run inference function\n",
    "        prediction_map = self.inference(image)\n",
    "\n",
    "        # single task model\n",
    "        if len(prediction_map) == 1:\n",
    "            # return first and only prediction array in the list\n",
    "            return prediction_map[0]\n",
    "\n",
    "        # multi task model\n",
    "        else:\n",
    "            # concatenate prediction results\n",
    "            # assumes that the tasks all output prediction arrays of same dimension on H and W\n",
    "            result_array = np.concatenate(prediction_map, axis=1)\n",
    "            return result_array\n",
    "\n",
    "    def apply(self, tile):\n",
    "        tile.image = self.F(tile.image)\n",
    "\n",
    "\n",
    "class HaloAIInference(Inference):\n",
    "    \"\"\"Transformation to run inferrence on HALO AI ONNX model.\n",
    "\n",
    "    Assumptions:\n",
    "        - Assumes that the ONNX model returns a tensor in which there is one prediction map for each class\n",
    "        - For example, if there are 5 classes, the ONNX model will output a (1, 5, Height, Weight) tensor\n",
    "        - If you select to argmax the classes, the class assumes a softmax or sigmoid has already been applied\n",
    "        - HaloAI ONNX models always have 20 class maps so you need to index into the first x maps if you have x classes\n",
    "\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to ONNX model w/o initializers,\n",
    "        num_classes (int): number of classes in the data,\n",
    "        input_name (str): name of the input the ONNX model accepts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path=None,\n",
    "        input_name=\"data\",\n",
    "        num_classes=None,\n",
    "        model_type=None,\n",
    "        local=True,\n",
    "    ):\n",
    "        super().__init__(model_path, input_name, num_classes, model_type, local)\n",
    "\n",
    "        self.model_card[\"num_classes\"] = self.num_classes\n",
    "        self.model_card[\"model_type\"] = self.model_type\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Class to handle HALO AI ONNX model locally stored at {self.model_path}\"\n",
    "\n",
    "    def F(self, image):\n",
    "        prediction_map = self.inference(image)\n",
    "\n",
    "        prediction_map = prediction_map[0][:, 0 : self.num_classes, :, :]\n",
    "\n",
    "        return prediction_map\n",
    "\n",
    "    def apply(self, tile):\n",
    "        tile.image = self.F(tile.image)\n",
    "\n",
    "\n",
    "# class to handle remote onnx models\n",
    "class RemoteTestHoverNet(Inference):\n",
    "    \"\"\"Transformation to run inferrence on ONNX model.\n",
    "\n",
    "    Citation for model:\n",
    "    Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D.\n",
    "    TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): temp file name to download onnx from huggingface,\n",
    "        input_name (str): name of the input the ONNX model accepts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path=\"temp.onnx\",\n",
    "        input_name=\"data\",\n",
    "        num_classes=5,\n",
    "        model_type=\"Segmentation\",\n",
    "        local=False,\n",
    "    ):\n",
    "        super().__init__(model_path, input_name, num_classes, model_type, local)\n",
    "\n",
    "        # specify URL of the model in PathML public repository\n",
    "        url = \"https://huggingface.co/pathml/test/resolve/main/hovernet_fast_tiatoolbox_fixed.onnx\"\n",
    "\n",
    "        # download model, save as temp.onnx\n",
    "        with open(self.model_path, \"wb\") as out_file:\n",
    "            content = requests.get(url, stream=True).content\n",
    "            out_file.write(content)\n",
    "\n",
    "        self.model_card[\"num_classes\"] = self.num_classes\n",
    "        self.model_card[\"model_type\"] = self.model_type\n",
    "        self.model_card[\"name\"] = \"Tiabox HoverNet Test\"\n",
    "        self.model_card[\"model_input_notes\"] = \"Accepts tiles of 256 x 256\"\n",
    "        self.model_card[\n",
    "            \"citation\"\n",
    "        ] = \"Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D. TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Class to handle remote TIAToolBox HoverNet test ONNX. See model card for citation.\"\n",
    "\n",
    "    def apply(self, tile):\n",
    "        tile.image = self.F(tile.image)\n",
    "\n",
    "    def remove(self):\n",
    "        # remove the temp.onnx model\n",
    "        os.remove(self.model_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b28c79e-2453-42e5-9280-6c0d3ee082c0",
   "metadata": {},
   "source": [
    "## Try it Yourself!\n",
    "\n",
    "- What you need:\n",
    "    - An ONNX model stored locally\n",
    "    - An image with which you want to run inference stored locally\n",
    "    - PathML already downloaded \n",
    "\n",
    "- Make sure to define the `Inference` class and `remove_initializer_from_input` above in the previous seciton if you have not downloaded the latest version of PathML.\n",
    "\n",
    "- You will need to define the following variables: \n",
    "    - `slide_path`: 'PATH TO SLIDE'\n",
    "    - `model_path`: 'PATH TO ONNX MODEL'\n",
    "    - `new_path`: 'PATH TO SAVE FIXED ONNX MODEL'\n",
    "    - `num_classes`: 'NUMBER OF CLASSES IN YOUR DATASET'\n",
    "    - `tile_size`: 'TILE SIZE THAT YOUR ONNX MODEL ACCEPTS'\n",
    "    \n",
    "- The code in the cell below assumes you want the images passed in as is. If you need to select channels, you will need to add another `transform` method to do so before the inference transform. The following code provides an example if you want to subset into the first channel of an image. *Remember that PathML reads images in as XYZCT.* \n",
    "\n",
    "```python \n",
    "class convert_format(Transforms.Transform):\n",
    "    def F(self, image):\n",
    "        # orig = (1280, 1280, 1, 6, 1) = (XYZCT)\n",
    "        image = image[:, :, :, 0, ...] # this will make the tile (1280, 1280, 1, 1)\n",
    "        return image\n",
    "\n",
    "    def apply(self, tile):\n",
    "        tile.image = self.F(tile.image)\n",
    "        \n",
    "convert = convert_format()\n",
    "inference = Inference(\n",
    "    model_path = 'PATH TO LOCAL MODEL', \n",
    "    input_name = 'data', \n",
    "    num_classes = 'NUMBER OF CLASSES' , \n",
    "    model_type = 'CLASSIFICATION OR SEGMENTATION', \n",
    "    local = True)\n",
    "\n",
    "transformation_list = [convert, inference] \n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afe45989",
   "metadata": {},
   "source": [
    "### Converting a Pytorch Model to ONNX Using the `convert_pytorch_onnx` Function\n",
    "\n",
    "Note the following:\n",
    "- Similar to PyTorch, you will need to define and create an instance of you model class before loading the `.pt` file. Then you will need to set it to eval mode before calling the conversion function. The code to do these steps is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model class\n",
    "num_input, num_output, batch_size = 10, 1, 1\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleModel, self).__init__()\n",
    "    self.linear = torch.nn.Linear(num_input, num_output)\n",
    "    torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "  def forward(self, x):\n",
    "    y = self.linear(x)\n",
    "    return y\n",
    "\n",
    "# Define your model var\n",
    "model = SimpleModel()\n",
    "\n",
    "# Export model as .pt if you haven't already done so\n",
    "# If you have already exported a .pt file, you will still need to define a model class, initialize it, and set it to eval mode. \n",
    "# If you saved your model using `torch.jit.script`, you will not need to define your model class and instead load it using `torch.jit.load` then set it to eval mode.\n",
    "torch.save(model, \"test.pt\")\n",
    "\n",
    "# Load .pt file\n",
    "model_test = torch.load(\"test.pt\")\n",
    "# Set model to eval mode\n",
    "model_test.eval()\n",
    "\n",
    "# Define a dummy tensor (this is an example of what the ONNX should expect during inference)\n",
    "x = torch.randn(batch_size, num_input)\n",
    "\n",
    "# Run conversion function\n",
    "convert_pytorch_onnx(model = model_test, dummy_tensor = x, model_name = \"NAME_OF_OUTPUT_MODEL_HERE.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcdeaac3-80ae-4e67-8aa9-8f4c637a92eb",
   "metadata": {},
   "source": [
    "### Local ONNX Model Using the `Inference` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2f84e-e554-4770-aad9-c51fa1890ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define slide path\n",
    "slide_path = 'PATH TO SLIDE'\n",
    "\n",
    "# Set path to model \n",
    "model_path = 'PATH TO ONNX MODEL'\n",
    "# Define path to export fixed model\n",
    "new_path = 'PATH TO SAVE NEW ONNX MODEL'\n",
    "\n",
    "\n",
    "# Fix the ONNX model\n",
    "remove_initializer_from_input(model_path, new_path) \n",
    "\n",
    "inference = Inference(model_path = new_path, input_name = 'data', num_classes = 'NUMBER OF CLASSES' , model_type = 'CLASSIFICATION OR SEGMENTATION', local = True)\n",
    "\n",
    "transformation_list = [inference] \n",
    "\n",
    "# Initialize pathml.core.slide_data.SlideData object\n",
    "wsi = SlideData(slide_path)\n",
    "\n",
    "# Set up PathML pipeline\n",
    "pipeline = Pipeline(transformation_list)\n",
    "\n",
    "# Run Inference\n",
    "# Level is equal to 0 for highest resolution (Note that this is the default setting)\n",
    "wsi.run(pipeline, tile_size = 'TILE SIZE THAT YOUR ONNX MODEL ACCEPTS', level = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc7902dc-0113-4604-abe4-6f3a8588c0b5",
   "metadata": {},
   "source": [
    "### Local ONNX Model Using the `HaloAIInference` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eedbf1-be61-440e-a044-6dce4c8de04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define slide path\n",
    "slide_path = 'PATH TO SLIDE'\n",
    "\n",
    "# Set path to model \n",
    "model_path = 'PATH TO ONNX MODEL'\n",
    "# Define path to export fixed model\n",
    "new_path = 'PATH TO SAVE NEW ONNX MODEL'\n",
    "\n",
    "\n",
    "# Fix the ONNX model\n",
    "remove_initializer_from_input(model_path, new_path) \n",
    "\n",
    "inference = HaloAIInference(model_path = new_path, input_name = 'data', num_classes = 'NUMBER OF CLASSES' , model_type = 'CLASSIFICATION OR SEGMENTATION', local = True)\n",
    "\n",
    "transformation_list = [inference] \n",
    "\n",
    "# Initialize pathml.core.slide_data.SlideData object\n",
    "wsi = SlideData(slide_path)\n",
    "\n",
    "# Set up PathML pipeline\n",
    "pipeline = Pipeline(transformation_list)\n",
    "\n",
    "# Run Inference\n",
    "# Level is equal to 0 for highest resolution (Note that this is the default setting)\n",
    "wsi.run(pipeline, tile_size = 'TILE SIZE THAT YOUR ONNX MODEL ACCEPTS', level = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "431abad0-10ff-44fe-ba56-eb6402ce8e4c",
   "metadata": {},
   "source": [
    "### Remote ONNX Using our `RemoteTestHoverNet` Class\n",
    "- Uses a Hovernet from [TIAToolbox](https://github.com/TissueImageAnalytics/tiatoolbox) \n",
    "- Note that the purpose of this model is to illustrate how PathML will handle future remote models. We plan on release more public models to our model zoo on HuggingFace in the future.\n",
    "- Citation for model:\n",
    "    - Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D. TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.\n",
    "- Make sure your image has 3 channels! \n",
    "- When the `RemoteTestHoverNet` is first initialized, it downloads the HoverNet from HuggingFace and saves it locally on your own system as `temp.onnx`. \n",
    "    - **You will need to remove it manually by calling the `remove()` method** An example of how to call this method is in the last line in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976d60b-6e78-42ca-a52d-489911e580f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define slide path\n",
    "slide_path = 'PATH TO SLIDE'\n",
    "\n",
    "inference = RemoteTestHoverNet()\n",
    "\n",
    "# Create a transformation list\n",
    "transformation_list = [\n",
    "    inference\n",
    "] \n",
    "\n",
    "# Initialize pathml.core.slide_data.SlideData object\n",
    "wsi = SlideData(slide_path)\n",
    "\n",
    "# Set up PathML pipeline\n",
    "pipeline = Pipeline(transformation_list)\n",
    "\n",
    "# Run Inference\n",
    "wsi.run(pipeline, tile_size = 256)\n",
    "\n",
    "# DELETE ONNX MODEL DOWNLOADED FROM HUGGINGFACE\n",
    "inference.remove() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "318ae957-73d8-4c7f-b87c-b012750eda10",
   "metadata": {},
   "source": [
    "## Iterate over the tiles\n",
    "\n",
    "Now that you have your tiles saved to your SlideData object, you can now iterate over them.\n",
    "\n",
    "For example, if you wanted to check the shape of the tiles you could run the following code: \n",
    "\n",
    "```python\n",
    "for tile in wsi.tiles: \n",
    "    print(tile.image.shape) \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc5c89ae-400e-4380-a717-12800fb77d97",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Pocock J, Graham S, Vu QD, Jahanifar M, Deshpande S, Hadjigeorghiou G, Shephard A, Bashir RM, Bilal M, Lu W, Epstein D. TIAToolbox as an end-to-end library for advanced tissue image analytics. Communications medicine. 2022 Sep 24;2(1):120.\n",
    "\n",
    "- https://github.com/microsoft/onnxruntime/blob/main/tools/python/remove_initializer_from_input.py"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "james_test2",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "james_test2",
   "language": "python",
   "name": "james_test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
